{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional energy threshold approach\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "audio_file_path = \"E:\\\\5305 assignment\\\\audio\\\\AlGore_2009.wav\"\n",
    "\n",
    "# Define frame length and hop length\n",
    "frame_length = int(0.025 * 22050)\n",
    "hop_length = int(0.010 * 22050)\n",
    "\n",
    "# Preprocess the audio file\n",
    "def preprocess_audio(audio_path):\n",
    "    # Load the audio file\n",
    "    audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
    "    # Frame the audio\n",
    "    frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length).T\n",
    "    return frames\n",
    "\n",
    "# Calculate the energy of an audio frame\n",
    "def frame_energy(frame):\n",
    "    return np.sum(frame ** 2) / len(frame)\n",
    "\n",
    "# Voice Activity Detection decision based on energy threshold\n",
    "def is_speech(frame, threshold):\n",
    "    return frame_energy(frame) > threshold\n",
    "\n",
    "# Calculate the energy threshold using the statistics of frame energies\n",
    "def calculate_energy_threshold(frames, factor=0.01):\n",
    "    energies = [frame_energy(frame) for frame in frames]\n",
    "    mean_energy = np.mean(energies)\n",
    "    std_energy = np.std(energies)\n",
    "    return mean_energy + factor * std_energy\n",
    "\n",
    "# Preprocess the single audio file\n",
    "frames = preprocess_audio(audio_file_path)\n",
    "print(f\"Processed {audio_file_path}\")\n",
    "\n",
    "# Calculate the adaptive energy threshold for the audio file\n",
    "energy_threshold = calculate_energy_threshold(frames)\n",
    "speech_flags = [is_speech(frame, energy_threshold) for frame in frames]\n",
    "num_speech_frames = sum(speech_flags)\n",
    "num_total_frames = len(frames)\n",
    "\n",
    "print(f\"VAD applied on {audio_file_path}\")\n",
    "print(f\"Detected {num_speech_frames} speech frames out of {num_total_frames}\")\n",
    "\n",
    "# Plotting the energy of the frames\n",
    "energies = [frame_energy(frame) for frame in frames]\n",
    "time = np.arange(len(energies)) * (hop_length / 22050)  # Convert frame index to seconds\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(time, energies, label='Frame Energy')\n",
    "plt.axhline(y=energy_threshold, color='r', linestyle='--', label='Energy Threshold')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Energy')\n",
    "plt.title('Frame Energy over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive threshold approach\n",
    "\n",
    "audio_file_path = \"E:\\\\5305 assignment\\\\audio\\\\AlGore_2009.wav\"\n",
    "\n",
    "frame_length = int(0.025 * 22050)\n",
    "hop_length = int(0.010 * 22050)\n",
    "\n",
    "def preprocess_audio(audio_path):\n",
    "    # Load the audio file\n",
    "    audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
    "    # Frame the audio\n",
    "    frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length).T\n",
    "    return frames, sample_rate\n",
    "\n",
    "# Calculate the energy of an audio frame\n",
    "def frame_energy(frame):\n",
    "    return np.sum(frame ** 2) / len(frame)\n",
    "\n",
    "# Calculate the energy threshold using the statistics of frame energies\n",
    "def calculate_energy_threshold(frames, noise_percentile=1, speech_percentile=96):\n",
    "    # Compute the short-term energy of each frame\n",
    "    frame_energies = np.array([frame_energy(frame) for frame in frames])\n",
    "\n",
    "    # Estimate the noise energy level using a low percentile\n",
    "    noise_energy = np.percentile(frame_energies, noise_percentile)\n",
    "\n",
    "    # Estimate speech energy level using a high percentile\n",
    "    speech_energy = np.percentile(frame_energies, speech_percentile)\n",
    "\n",
    "    # Use a value between noise and speech energy as the threshold\n",
    "    threshold = np.sqrt(noise_energy * speech_energy)\n",
    "\n",
    "    return threshold, frame_energies\n",
    "\n",
    "# Determine if a frame contains speech\n",
    "def is_speech(frame, threshold):\n",
    "    return frame_energy(frame) > threshold\n",
    "\n",
    "frames, sample_rate = preprocess_audio(audio_file_path)\n",
    "print(f\"Processed {audio_file_path}\")\n",
    "\n",
    "energy_threshold, frame_energies = calculate_energy_threshold(frames)\n",
    "speech_flags = [is_speech(frame, energy_threshold) for frame in frames]\n",
    "num_speech_frames = sum(speech_flags)\n",
    "num_total_frames = len(frames)\n",
    "\n",
    "print(f\"VAD applied on {audio_file_path}\")\n",
    "print(f\"Detected {num_speech_frames} speech frames out of {num_total_frames}, which is {num_speech_frames/num_total_frames:.2%} of the total frames.\")\n",
    "\n",
    "# Plot the energy threshold graph\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(frame_energies, label='Frame energy')\n",
    "plt.axhline(energy_threshold, color='red', linestyle='--', label='Energy threshold')\n",
    "plt.xlabel('Frame index')\n",
    "plt.ylabel('Energy')\n",
    "plt.legend()\n",
    "plt.title('Frame Energies with Energy Threshold')\n",
    "plt.show()\n",
    "\n",
    "# Plot the speech activity graph\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(speech_flags, label='Speech activity (1=Speech, 0=Non-speech)')\n",
    "plt.xlabel('Frame index')\n",
    "plt.ylabel('Speech Flag')\n",
    "plt.title('Speech Activity Detection')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
